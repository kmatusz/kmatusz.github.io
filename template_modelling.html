<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Template for ML modelling</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Kamil Matuszelański</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">About me</a>
</li>
<li>
  <a href="toc.html">Projects</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Template for ML modelling</h1>

</div>


<p>Using machine learning is a highly repetitive process. In this notebook I tried to create unified template to save typing time in my next projects. Most of the time it’s as easy as changing input dataset, and in other cases it is also helpful as a reminder of steps to make.</p>
<div id="basics" class="section level4">
<h4>Basics</h4>
<pre class="r"><code>library(tidyverse)
library(caTools)
library(ROCR)
library(caret)</code></pre>
<p>Here we assign our dataset to name <em>df</em> and changing the target column name to <em>TARGET</em></p>
<pre class="r"><code>df &lt;- read.csv(&quot;Train.csv&quot;, stringsAsFactors = F)
df&lt;-df%&gt;%select(-Loan_ID)
name_target&lt;-&quot;Loan_Status&quot;
names(df)[which(names(df)==name_target)]&lt;-&quot;TARGET&quot;</code></pre>
<p>Here is the place for explanatory data analysis. As this process is highly dependent on the dataset, I included only small chunk.</p>
<pre class="r"><code>df%&gt;%summary()</code></pre>
<pre><code>##     Gender            Married           Dependents       
##  Length:614         Length:614         Length:614        
##  Class :character   Class :character   Class :character  
##  Mode  :character   Mode  :character   Mode  :character  
##                                                          
##                                                          
##                                                          
##                                                          
##   Education         Self_Employed      ApplicantIncome CoapplicantIncome
##  Length:614         Length:614         Min.   :  150   Min.   :    0    
##  Class :character   Class :character   1st Qu.: 2878   1st Qu.:    0    
##  Mode  :character   Mode  :character   Median : 3812   Median : 1188    
##                                        Mean   : 5403   Mean   : 1621    
##                                        3rd Qu.: 5795   3rd Qu.: 2297    
##                                        Max.   :81000   Max.   :41667    
##                                                                         
##    LoanAmount    Loan_Amount_Term Credit_History   Property_Area     
##  Min.   :  9.0   Min.   : 12      Min.   :0.0000   Length:614        
##  1st Qu.:100.0   1st Qu.:360      1st Qu.:1.0000   Class :character  
##  Median :128.0   Median :360      Median :1.0000   Mode  :character  
##  Mean   :146.4   Mean   :342      Mean   :0.8422                     
##  3rd Qu.:168.0   3rd Qu.:360      3rd Qu.:1.0000                     
##  Max.   :700.0   Max.   :480      Max.   :1.0000                     
##  NA&#39;s   :22      NA&#39;s   :14       NA&#39;s   :50                         
##     TARGET         
##  Length:614        
##  Class :character  
##  Mode  :character  
##                    
##                    
##                    
## </code></pre>
<pre class="r"><code>df$TARGET%&gt;%summary()</code></pre>
<pre><code>##    Length     Class      Mode 
##       614 character character</code></pre>
</div>
<div id="preprocessing" class="section level4">
<h4>Preprocessing</h4>
<p>Now it’s time for preprocessing the dataset to suit Caret package methodology. First step is cropping the dataset. Use this step only if you encounter memory usage problems during fitting the model.</p>
<pre class="r"><code>#index_head&lt;-createDataPartition(df$TARGET, p =0.005, list = F) #experiment with p value, the more data you leave unchaged the better for the accuracy.
#df_small&lt;-df[index_head,]
df_small&lt;-df</code></pre>
</div>
<div id="dealing-with-missing-values" class="section level3">
<h3>Dealing with missing values</h3>
<p>There are quite a few approaches to deal with missing values, and the question what to do is highly case-dependent. Here I’m using median imputation for numeric variables and changing NA value to “na” string in text variables. Using this technique you will probably obtain some reasonable baseline to test out another ideas.</p>
<pre class="r"><code>df_small%&gt;%
  mutate_if(is.numeric,function(x) ifelse(is.na(x), quantile(x, 0.5, na.rm=T)%&gt;%as.numeric(), x))%&gt;%   #numeric variables
  mutate_if(function(x) !is.numeric(x), function(x) ifelse(is.na(x), &quot;na&quot;, x))-&gt;df_small</code></pre>
<p>Next step is using dummy variables to encode strings as numbers. This is versatile approach that will work using every model, but this step isn’t always necessary as some models (decision trees for example) can also deal with categorical variables.</p>
<pre class="r"><code>dummies &lt;- dummyVars(TARGET ~ ., data = df_small)
df_small_dum&lt;-predict(dummies, df_small)%&gt;%as.data.frame()
df_small_dum$TARGET&lt;-as.factor(df_small$TARGET)
df_small&lt;-df_small_dum
rm(df_small_dum)</code></pre>
<p>The dataset is almost ready to modelling. Other steps to add would be for example dimensionality reduction using PCA.</p>
<p>Creating training and test sets:</p>
<pre class="r"><code>index_train&lt;-createDataPartition(df_small$TARGET, p=0.7, list=F)
training&lt;-df_small[index_train, ]
test&lt;-df_small[-index_train, ]</code></pre>
<p>To save execution time good idea is to save preprocessed dataset to a file.</p>
<pre class="r"><code>save.image(&quot;data_preprocessed.Rdata&quot;)
#load(&quot;data_preprocessed.RData&quot;)</code></pre>
</div>
<div id="modelling" class="section level2">
<h2>Modelling</h2>
<p>And now the funniest part. Creating models and evaluation using caret package is a piece of cake. A standard approach would be to define training control (in this case repeatedCV) and use it iteratively using different models to obtain better and better results. Last step is comparing the models using resampling and choosing the winner.</p>
<pre class="r"><code>library(gbm)
tr_cont&lt;- trainControl(method=&quot;repeatedcv&quot;, 
                       #add these two lines if you are using AUC as  a metric:
                       #summaryFunction = twoClassSummary, 
                       #classProbs = T, 
                      repeats=2, number=2)</code></pre>
<div id="model-1--gbm" class="section level4">
<h4>Model 1- gbm</h4>
<pre class="r"><code>model1&lt;-train(TARGET~. , data= training,
              method=&quot;gbm&quot;,
              verbose=F,
              #metric=&quot;ROC&quot;,
              trControl=tr_cont
              )</code></pre>
<p>Checking performance and stats of the model</p>
<pre class="r"><code>model1</code></pre>
<pre><code>## Stochastic Gradient Boosting 
## 
## 431 samples
##  24 predictor
##   2 classes: &#39;N&#39;, &#39;Y&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (2 fold, repeated 2 times) 
## Summary of sample sizes: 215, 216, 215, 216 
## Resampling results across tuning parameters:
## 
##   interaction.depth  n.trees  Accuracy   Kappa    
##   1                   50      0.8201604  0.5143957
##   1                  100      0.8155308  0.5066546
##   1                  150      0.8108850  0.4963489
##   2                   50      0.8120317  0.4988939
##   2                  100      0.7899978  0.4589649
##   2                  150      0.7911606  0.4664259
##   3                   50      0.8027724  0.4810743
##   3                  100      0.7911660  0.4636118
##   3                  150      0.7783969  0.4417704
## 
## Tuning parameter &#39;shrinkage&#39; was held constant at a value of 0.1
## 
## Tuning parameter &#39;n.minobsinnode&#39; was held constant at a value of 10
## Accuracy was used to select the optimal model using the largest value.
## The final values used for the model were n.trees = 50, interaction.depth
##  = 1, shrinkage = 0.1 and n.minobsinnode = 10.</code></pre>
<pre class="r"><code>#plot(model1)</code></pre>
<pre class="r"><code>varImp(model1)%&gt;%plot()</code></pre>
<p><img src="template_modelling_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>
<div id="model-2--glm" class="section level4">
<h4>Model 2- glm</h4>
<pre class="r"><code>model2&lt;-train(TARGET~. , data= training,
              method=&quot;glm&quot;, 
              #metric=&quot;ROC&quot;,
              family=binomial(), #this is a parameter of glm model, to remove in other models
              trControl=tr_cont
              )</code></pre>
<p>Checking performance and stats of the model</p>
<pre class="r"><code>model2</code></pre>
<pre><code>## Generalized Linear Model 
## 
## 431 samples
##  24 predictor
##   2 classes: &#39;N&#39;, &#39;Y&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (2 fold, repeated 2 times) 
## Summary of sample sizes: 216, 215, 215, 216 
## Resampling results:
## 
##   Accuracy   Kappa    
##   0.8143842  0.5122778</code></pre>
<pre class="r"><code>varImp(model2)%&gt;%plot()</code></pre>
<p><img src="template_modelling_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>… and so on. Once the schema is right, adding new models to test is as easy as copying few lines and changing name of the model.</p>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
